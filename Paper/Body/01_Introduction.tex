\section{Introduction}

\begin{quote}
\textit{"Failure to conclude that a model is false must be a failure of our imagination, not a success of the model."}
\hfill --- \cite{mcelreath2018statistical}
\end{quote}

Experimental designs are increasingly used in the social and behavioral sciences in estimating the causal effects of various interventions. The randomized controlled trial (RCT) is widely regarded to be the `gold standard' when it comes to estimating the causal effects of treatment as opposed to estimates from an observational study. Typically, participants are divided into distinct treatment and control groups, allowing for straightforward comparisons of intervention outcomes in RCTs.\footnote{This design is called \bsd{} in some fields since interventions are randomly assigned between subjects \citep{02_maxwell2017designing}.} However, this conventional approach is not the only experimental design used.

\Wsd{}, also known as repeated-measures design, offers an alternative that exposes all participants to every condition in a study. This design is sometimes used in fields such as experimental psychology \citep{keren2014between}, management sciences \citep{Lane2024}, political science \citep{09_Clifford}, and even medical trials \citep{Sarkies2019}, which enables researchers to compare responses across treatments for the same individuals. Experimenters often employ these methods when they face logistical challenges in recruitment, implementation (particularly regarding the costs associated with specific trials), or when the population concerned is relatively small, and the experimenter wishes to ensure there is \textit{common support} in terms of the exposure of the treatment with respect to the covariates (\citealp{02_maxwell2017designing}; \citealp{ErlebacherAlbert1977Daao}). However, this experimental design introduces challenges in causal inference. 

For example, imagine a study testing the effect of background music on concentration. Participants complete two problem-solving tasks: one in silence and one with music. If every participant always does the silent condition first and the music condition second, any observed difference in performance might not be due to the music itself but rather to other factors. For instance, they might perform better in the second task simply because they have become more familiar with the problem format (a practice effect) or worse due to mental fatigue. Since these order-related influences are confounded with the treatment, the researcher cannot tell whether any observed changes are truly caused by the music or just by the passage of time and repeated testing. The chief culprit confounding the estimate of the treatment effect in within-subjects designs are \emph{carryover effects}, which are the residual effects from the first period that influence responses in the second period \citep{02_maxwell2017designing}.

To address these concerns, counterbalancing is often applied to within-subjects designs. In clinical trials, this design is also known as crossover trials or AB/BA designs \citep{ZHANG2022_crossovertrials, sibbald1998understanding, matthew_multiperiod_crossover}. This approach randomizes the order of treatment and control conditions for participants, assuming that this would cancel out any carryover effects, resulting in an unbiased estimate. Figure \ref{fig:CWSD_Figure} shows how a \cwsd{} is implemented in the case where there are two experimental conditions. However, this assumption is often overly optimistic. Counterbalancing assumes that carryover effects are symmetric and cancel out, yet this symmetry is unverifiable \emph{a priori}. Differential carryover effects, where one condition's impact persists or interacts with subsequent conditions in an asymmetric manner, can bias estimates of the average treatment effect even when participants are properly counterbalanced.

There are some advantages in using within-subjects design in some empirical settings, as it aligns more naturally with economic and psychological theories that model how individuals respond to changing conditions. For example, in empirical studies testing utility theories and preference, participants might exposed to multiple conditions of the study, allowing the experimenter to observe how an individual makes such a tradeoff \citep{09_Charness}. 

Despite their inferential limitations, counterbalanced within-subjects designs offer several practical advantages. They allow researchers to collect multiple observations per participant, improving statistical efficiency—especially useful when working with small populations or when recruitment is costly or difficult, such as in studies involving venture capitalists \citep{Lane2024}. In such cases, a between-subjects design may suffer from issues like limited overlap or lack of common support across covariates, making within-subjects designs an attractive alternative despite their potential identification problems.

In this paper, we analyze the implications of using counterbalanced within-subjects designs for causal inference, analyzing the problem with the potential outcomes framework. Specifically, we first explore the assumptions required in \cwsd{} to produce treatment effect estimates \emph{consistent} with those obtained from \bsd{} in the case of two discrete time periods, with the goal of estimating the Average Treatment Effect (ATE) as defined in the potential outcomes framework. We then introduce \textit{sequential exchangeability} as a generalized assumption required, alongside the standard assumptions of the Rubin Causal Model, to identify the causal effects of treatment in other sequential designs similar to a counterbalanced within-subjects design. We introduce sequential randomization and selective sequential randomization in Section \ref{sec: seq_exchangeability_alt_design} as alternative sequential designs where the assumptions of \textit{sequential exchangeability} is more credible than the commonly used \cwsd{}.

Sequential designs are often used to improve the efficiency and reliability of experiments. For example, \cite{04_whitehead2020estimation} use a design that allows dropping underperforming treatments mid-trial, \cite{08_zhou2018sequential} propose a rerandomization method to improve covariate balance over time, and \cite{03_tamura2011estimation} apply a sequential parallel design to reduce placebo effects. While these approaches differ in motivation, they all rely on using data collected across stages to better estimate treatment effects. We focus on how similar ideas apply to counterbalanced within-subjects designs and relate \textit{sequential exchangeability} as a condition under which such designs can identify the average treatment effect (ATE).

We want to emphasize that such assumptions are typically difficult to verify \emph{a priori} and hence, we do not advocate the use of such experimental designs to estimate ATE, even in the case of sequential randomization where the assumptions are more credible. However, in situations where such a design is required due to the aforementioned logistical challenges, we provide a way to reason, and guidance to ensure that the treatment effects are properly estimated.

Our work builds on existing work of analyzing experimental designs within the potential‐outcomes framework such as in mediation analysis, factorial designs, and conjoint studies, by making explicit the precise causal assumptions each design invokes. In mediation analysis, for example, researchers decompose a treatment’s total effect into direct and indirect pathways under a sequential ignorability assumption that links potential mediators and outcomes \citep{imai2013experimental,11_imai2010general}. Conjoint analysis, meanwhile, treats each attribute as a component ``treatment,'' isolating marginal contributions and interactions via randomized component assignment and carefully articulated exclusion restrictions \citep{egami2019causal}. In the same spirit, our paper examines counterbalanced within-subjects design to ask: what is the set of causal assumptions required to point‐identify the ATE in counterbalanced within‐subject designs? By iterating these identifying assumptions in full generality, we extend the potential‐outcomes framework to reason for arbitrary, higher‐order carryover and learning effects, rather than relying on the narrow parametric or symmetry conditions typical of two‐period crossover estimators \citep{23_AnalysisOfCrossoverTrial}.

The paper is organized as follows. Section \ref{sec: identification_assumption} outlines the identification assumptions required in a counterbalanced within-subjects design and provides illustrative examples of when these assumptions might be violated. Section \ref{sec: seq_exchangeability_alt_design} generalizes the assumptions and introduce the concept of sequential exchangeability, as well as alternative sequential designs where the assumptions are more credible. Section \ref{sec: what_can_we_do} discusses heuristic checks to verify whether violations of the assumptions occur and explores ways to recover an unbiased causal estimate using simulations under certain additional assumptions. Section \ref{sec: conclusion} concludes the paper.